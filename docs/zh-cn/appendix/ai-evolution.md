# 人工智能进化史：从 "逻辑" 到 "直觉" (Interactive Intro)

> 💡 **学习指南**：本章节通过交互式演示，带你梳理人工智能 70 年的发展脉络。从最早的下棋程序，到今天能写诗作画的 ChatGPT。

<AiEvolutionDemo />

## 0. 引言：机器能思考吗？

图灵在 1950 年提出了这个问题。
为了回答它，人类进行了长达半个多世纪的探索。

我们走过弯路（试图穷举规则），也经历过寒冬（算力不足），最终在模仿人脑（神经网络）的道路上取得了突破。

---

## 1. 符号主义：教机器"守规矩" (1950s - 1980s)

早期的 AI 科学家认为：智慧就是**逻辑推理**。
只要我们把世界上的所有知识都写成 `If...Then...` 的规则，机器就能像人一样聪明。

这被称为**专家系统 (Expert Systems)**。

### 1.1 什么是"基于规则"？
就像教小孩：
*   如果看到红灯，就停下。
*   如果下雨，就带伞。

### 1.2 交互演示：规则 vs 学习
下方的演示展示了两种方式的区别。
*   **左边 (规则)**：你必须显式地写代码 `if (size > 6)`。如果世界变了（比如苹果变小了），你的代码就失效了。
*   **右边 (学习)**：你不需要写规则。你只需要给机器看一堆苹果和樱桃的数据，点击 **Train**，它自己会"悟"出一个分界线。

<RuleBasedVsLearningDemo />

**局限性**：你能写出"识别猫"的规则吗？
"有胡须"？老鼠也有。"有尖耳朵"？狗也有。
现实世界太复杂，规则写不完。这就是符号主义 AI 衰落的原因。

---

## 2. 连接主义：教机器"像人脑一样思考" (2010s+)

既然规则写不完，不如让机器自己学？
科学家开始模仿人脑的结构——**神经元**。

### 2.1 感知机 (Perceptron)
这是最简单的神经元模型。它接收多个输入，根据**权重 (Weight)** 加权求和，如果超过某个**阈值 (Bias)**，就激活。

$$ Output = \begin{cases} 1 & \text{if } \sum (w_i \cdot x_i) + b > 0 \\ 0 & \text{otherwise} \end{cases} $$

听起来很复杂？动手试一下！

### 2.2 交互演示：玩转神经元
调整下方的 **Weights (权重)** 和 **Bias (偏置)**，看看能否控制神经元的输出。
*   **Weights ($w$)**：代表输入的"重要性"。$w$ 越大，这个输入对结果影响越大。
*   **Bias ($b$)**：代表神经元的"门槛"。$b$ 越小，神经元越容易兴奋（输出 1）。

<PerceptronDemo />

当几十亿个这样的神经元连接在一起，奇迹就发生了——这就是**深度学习 (Deep Learning)**。

---

## 3. 生成式 AI：机器有了"创造力" (2020s+)

以前的 AI 主要是**判别式**（这是猫还是狗？）。
现在的 AI 是**生成式**（画一只猫！）。

这一切的背后，是 **Transformer** 架构的诞生。它让 AI 学会了理解上下文，学会了"举一反三"。

> 关于大语言模型 (LLM) 的详细原理，请移步下一章：[大语言模型入门](./llm-intro.md)

---

## 4. 总结

| 时代 | 核心理念 | 代表产物 | 局限 |
| :--- | :--- | :--- | :--- |
| **符号主义** | 智慧 = 规则 | 深蓝 (下棋), 医疗诊断系统 | 无法处理模糊、复杂的现实世界 |
| **连接主义** | 智慧 = 神经网络 | AlphaGo, 人脸识别 | 需要海量数据，是个"黑盒" |
| **生成式 AI** | 智慧 = 通用理解 | ChatGPT, Midjourney | 幻觉 (一本正经胡说八道) |

AI 的进化，就是从"人工设定规则"到"机器自动学习数据"的过程。
